Topic,Count,Name,Representation,Representative_Docs
-1,396,-1_fibonacci_deep_phi_learning,"['fibonacci', 'deep', 'phi', 'learning', 'local learning', 'recognition', 'li lithium', 'deep learning', 'ruler', 'atomic']","['S = <phi, phi, phi> Training data = <square, pointy, white> => Yes (positive example). How will S be represented after encountering this training data? Initially, S contains phi, which implies that no example is positive. It encounters a positive example, which is inconsistent with the current hypothesis. So, it generalizes accordingly to approve the new example. It thus takes the values of the training instance. <phi, phi, phi> <square, pointy, white > <circular, blunt, black> <?, ?, ? >', 'S = < phi ,  phi ,  phi >\nTraining Data = <square, point, white> => Yes (positive example. How will S be represented after encountering this training data? Initially, S contains phi, which implies that no example is positive. It encounters a positive example, which is inconsistent with the current hypothesis. So, it generalizes accordingly to approve the new example. It thus takes the values of the training instance. < phi ,  phi ,  phi > <square, pointy, white> <circular, blunt, black> <?, ?, ?>', ""In computation, how does the Fibonacci sequence's worst-case input relate to Euclid's algorithm? Euclid's algorithm for finding the greatest common divisor (gcd) works by repeatedly finding remainders. The algorithm is at its slowest—the worst-case—when the remainders decrease as slowly as possible. In 1844, French mathematician Gabriel Lamé proved that the maximum number of steps required by Euclid's algorithm is proportional to the number of digits of the smaller input number, and this maximum occurs precisely when the two input numbers are consecutive Fibonacci numbers  open parenthesis F subscript k plus 1 and F subscript k close parenthesis . This is because F subscript k plus 1\xa0mod\xa0F subscript k  equals  F subscript k plus 1 −F subscript k  equals F subscript k−1, leading to the minimum possible decrease in the arguments at each step. Pairs of consecutive Fibonacci numbers represent the worst-case input for gcd calculations. Only the first two Fibonacci numbers affect Euclid's algorithm performance. Pairs of prime Fibonacci numbers represent the worst-case inputs only. Fibonacci numbers cause Euclid's algorithm to run in constant time.""]"
0,1487,0_cell_energy_dna_chromosomes,"['cell', 'energy', 'dna', 'chromosomes', 'proteins', 'carbon', 'genetic', 'meiosis', 'cell division', 'mitosis']","['Which processes or molecules are involved in regenerating ATP during the light reactions? ATP regeneration, or photophosphorylation, occurs when light energy creates a proton gradient (high concentration of H^+) across the thylakoid membrane. The potential energy stored in this gradient is then harnessed by the enzyme ATP synthase, which allows protons to flow back down their concentration gradient, driving the phosphorylation of ADP to produce ATP. The other molecules listed—Acetyl-CoA, Phosphofructokinase, and Ribulose\xa0bisphosphate\xa0carboxylase (RuBisCO)—are all involved in other metabolic pathways: Acetyl-CoA is key in cellular respiration and fatty acid metabolism, while Phosphofructokinase and RuBisCO are critical enzymes in glycolysis and the Calvin cycle (RuBisCO in the latter), respectively, making them incorrect for the direct regeneration of ATP during the light reactions. ATP synthase Proton gradient across the thylakoid membrane Acetyl-CoA Phosphofructokinase Ribulose bisphosphate carboxylase (RuBisCO)', 'Under which conditions do both the light reactions and carbon-fixation reactions stop in photosynthetic organisms? The Calvin cycle is the light-independent stage, but it is entirely dependent on the energy-rich products, ATP and NADPH, generated by the light-dependent reactions; in the dark, light reactions stop, and the supply of these molecules is quickly depleted, stalling the cycle. Additionally, several key enzymes within the Calvin cycle are naturally inactivated in the dark to prevent wasteful consumption of ATP and NADPH by running reverse or counterproductive reactions (like photorespiration), directly leading to the cessation of carbon fixation. The options of Oxygen accumulation, Carbon\xa0dioxide deficiency, or RuBisCO degradation are incorrect because carbon dioxide is generally available, and the primary immediate constraint in the dark is the lack of chemical energy (ATP and NADPH) and the regulatory shutdown of enzymes When NADPH from the light reactions is unavailable When ATP from the light reactions is unavailable In the absence of light At night when CO2 is present When glucose is absent When oxygen is absent', 'Which outcomes occur as electrons move down the mitochondrial electron transport chain? the primary function of the mitochondrial electron transport chain (ETC) is to harness the energy released by electrons as they move down a chain of protein complexes. This energy is used to actively pump protons (H^+) into the intermembrane space, which establishes a proton gradient across the inner mitochondrial membrane. The potential energy stored in this gradient, known as the proton-motive force, is then utilized by the enzyme ATP synthase to drive the synthesis of ATP from ADP and inorganic phosphate  open parenthesis P subscript i close parenthesis  in a process called chemiosmosis. The incorrect options describe the reduction of FAD (which happens before the ETC) and an increased O subscript 2  concentration (which is incorrect since O subscript 2 is the final electron acceptor and is consumed). A proton gradient is established across the inner mitochondrial membrane. ATP synthase uses proton-motive force to produce ATP from ADP and Pᵢ. FADH₂ is synthesized from FAD. O₂ concentration increases in the matrix.']"
1,824,1_data_regression_trees_algorithm,"['data', 'regression', 'trees', 'algorithm', 'variable', 'classification', 'overfitting', 'statements true', 'predictors', 'models']","['Which of the following statements is true about stochastic gradient descent? Stochastic Gradient Descent (SGD) is an optimization algorithm used to find the minimum of a function. The key characteristic that distinguishes it from other methods like Batch Gradient Descent is that it updates the model\'s parameters after processing each individual training example. This makes it computationally efficient and much faster than Batch Gradient Descent for large datasets, as it doesn\'t need to process the entire dataset before making a single update. While this can lead to a more ""noisy"" convergence path, it is often the preferred method for training large-scale deep learning models. It processes one training example per iteration It is not preferred, if the number of training examples is large It processes all the training examples for each iteration of gradient descent It is computationally very expensive, if the number of training examples is large', 'Which of the following statements is false about Ensemble learning? Ensemble learning is not an unsupervised learning algorithm. It is a supervised learning algorithm that combines several machine learning techniques into one predicitive model to decrease variance and bias. It can be trained and then used to make predictions. And this ensemble can be shown to have more flexibility in the functions they can represent It is a supervised learning algorithm It is an unsupervised learning algorithm More random assignments can be used to produce a stronger ensemble Enbsembles can be shown to have more flexibility in the functions they can represent', 'Which of the following statements is false about Ensemble learning? Ensemble learning is not an unsupervised learning algorithm. It is a supervised learning algorithm that combines several machine learning techniques into one predictive model to decrease variance and bias. It can be trained and then used to make predictions. And this ensemble can be shown to have more flexibility in the functions they can represent. It is a supervised learning algorithm More random algorithms can be used to produce a stronger ensemble It is an unsupervised learning algorithm Ensembles can be shown to have more flexibility in the functions they can represent']"
2,564,2_open parenthesis_parenthesis close parenthesis_open parenthesis close parenthesis_open parenthesis close,"['open parenthesis', 'parenthesis close parenthesis', 'open parenthesis close parenthesis', 'open parenthesis close', 'power minus', 'square root', 'close parenthesis equals', 'parenthesis power', 'sud sud sud', 'parenthesis minus']","[""Factor the trinomial: x to the power of 2  minus  5x  plus  6 The first step in setting up our binomial is to figure out our\r\npossible leading terms. In this case, the only reasonable factors of\r\nx to the power of 2 are x  times x:\r\nx to the power of 2  minus  5x  plus  6  equals   open parenthesis x  plus   dots  close parenthesis  open parenthesis x  plus   dots  close parenthesis \r\nNext, find the factors of 6. In this case, we could have 6  times 1 or 3  times 2.\r\nEither combination can potentially produce 5x, so the signage is\r\nimportant here.\r\nNote that since the last term in the ordered trinomial is positive,\r\nboth factors must have the same sign. Further, since the middle\r\nterm in the ordered trinomial is negative, we know the signs\r\nmust both be negative.\r\nTherefore, we have two possibilities,  open parenthesis x  minus  1 close parenthesis  open parenthesis x  minus  6 close parenthesis  or\r\n open parenthesis x  minus  3 close parenthesis  open parenthesis x  minus  2 close parenthesis .\r\nLet's solve for both, and check against the original trinomial.\r\n open parenthesis x  minus  1 close parenthesis  open parenthesis x  minus  6 close parenthesis   equals   open parenthesis x to the power of 2  minus  x  minus  6x  plus  6 close parenthesis   equals   open parenthesis x to the power of 2  minus  7x  plus  6 close parenthesis   not equal to x to the power of 2  minus  5x  plus  6\r\n open parenthesis x  minus  3 close parenthesis  open parenthesis x  minus  2 close parenthesis   equals   open parenthesis x to the power of 2  minus  3x  minus  2x  plus  6 close parenthesis   equals   open parenthesis x to the power of 2  minus  5x  plus  6 close parenthesis \r\nThus, our factors are  open parenthesis x  minus  3 close parenthesis  and  open parenthesis x  minus  2 close parenthesis .  open parenthesis x  minus  3 close parenthesis  ,  open parenthesis x  minus  2 close parenthesis   open parenthesis x  plus  3 close parenthesis  ,  open parenthesis x  plus  2 close parenthesis   open parenthesis x  plus  3 close parenthesis  ,  open parenthesis x  minus  2 close parenthesis "", 'Create a cubic function that has roots at x equals 2,−3,0. x  equals  0, x  equals  2, x  equals   minus 3\r\nThis can be written as:\r\nx  equals  0, x  minus  2  equals  0, x  plus  3  equals  0\r\nMultiply the terms together:\r\nf open parenthesis x close parenthesis   equals  x open parenthesis x  minus  2 close parenthesis  open parenthesis x  plus  3 close parenthesis \r\nMultiply the first two terms:\r\nf open parenthesis x close parenthesis   equals   open parenthesis x to the power of 2  minus  2x close parenthesis  open parenthesis x  plus  3 close parenthesis ,\r\nFOIL:\r\nf open parenthesis x close parenthesis   equals  x to the power of 3  plus  3x to the power of 2  minus  2x to the power of 2  minus  6x\r\nCombine like terms:\r\nf open parenthesis x close parenthesis   equals  x to the power of 3  plus  x to the power of 2  minus  6x f open parenthesis x close parenthesis   equals  x to the power of 3  plus  x to the power of 2  minus  6x f open parenthesis x close parenthesis   equals  x to the power of 3  plus  2x to the power of 2  minus  6x f open parenthesis x close parenthesis   equals  x to the power of 3  minus  x to the power of 2  plus  6x f open parenthesis x close parenthesis   equals  6x to the power of 3  plus  2x to the power of 2  minus  6x', ""Derive the following function:\nf(x) = f open parenthesis x close parenthesis   equals    square root of 3  divided by x to the power of 3   -\\frac{7}{3\\sqrt[3]{{x}^{10}}} Step 1: Identify which is the numerator/dividend and which is the denominator/divisor. The numerator/dividend will be denoted as u while the denominator/divisor will be v.\n\nTherefore, we have\n\nu  equals   square root of 3 \nv  equals  x to the power of 3 Step 2: Derive u and v individually.\n\nThen, we have\n\nu  equals   square root of 3 \nu  equals  x to the power of  2 divided by 3 \nu'  equals   2 divided by 3 x to the power of  minus  1 divided by 3 \n\nv  equals  x to the power of 3\nv'  equals  3x to the power of 2 Step 3: Substitute u, u', v and v' into the quotient rule formula.\n\n d divided by dx  left  open parenthesis  u divided by v  right  close parenthesis   equals   vu'  minus  uv' divided by v to the power of 2 \n\n d divided by dx  left  open parenthesis  u divided by v  right  close parenthesis   equals    left  open parenthesis x to the power of 3 right  close parenthesis   times  left  open parenthesis  2 divided by 3 x to the power of  minus  1 divided by 3  right  close parenthesis   minus   left  open parenthesis x to the power of  2 divided by 3  right  close parenthesis   times  left  open parenthesis 3x to the power of 2 right  close parenthesis  divided by  left  open parenthesis x to the power of 3 right  close parenthesis  to the power of 2  Step 4: Simplify algebraically.\n\n d divided by dx  left  open parenthesis  u divided by v  right  close parenthesis   equals    left  open parenthesis x to the power of 3 right  close parenthesis   times  left  open parenthesis  2 divided by 3 x to the power of  minus  1 divided by 3  right  close parenthesis   minus   left  open parenthesis x to the power of  2 divided by 3  right  close parenthesis   times  left  open parenthesis 3x to the power of 2 right  close parenthesis  divided by  left  open parenthesis x to the power of 3 right  close parenthesis  to the power of 2 \n\n d divided by dx  left  open parenthesis  u divided by v  right  close parenthesis   equals    2 divided by 3 x to the power of  8 divided by 3   minus  3x to the power of  8 divided by 3  divided by x to the power of 6 \n\n d divided by dx  left  open parenthesis  u divided by v  right  close parenthesis   equals    minus  7 divided by 3 x to the power of  8 divided by 3  divided by x to the power of 6 \n\n d divided by dx  left  open parenthesis  u divided by v  right  close parenthesis   equals   minus   7 divided by 3 x to the power of  8 divided by 3  divided by x to the power of 6 \n\n d divided by dx  left  open parenthesis  u divided by v  right  close parenthesis   equals   minus  7 divided by 3x to the power of  10 divided by 3  \n\nThe final answer is:\n\nf' open parenthesis x close parenthesis   equals   minus  7 divided by 3 square root of 3  ""]"
3,422,3_times equals_times equals times equals_18 times_equals times equals,"['times equals', 'times equals times equals', '18 times', 'equals times equals', 'times equals times', 'times 13 equals', 'times 12 equals', 'times 13', '13 equals', 'equals times equals times']","['1 times 6 equals  6 1 times 6 equals 6', '4 times 1  equals  4 4 times 1  equals  4', '1 times 4  equals  4 1 times 4  equals 4']"
4,219,4_ridge_ridge regression_lasso_weights,"['ridge', 'ridge regression', 'lasso', 'weights', 'deep', 'selection', 'learning', 'regression', 'hidden units', 'backpropagation']","['Best subset selection is computationally feasible when the number of predictors p is very large, e.g., p  greater than  40. Best subset selection is computationally infeasible when the number of predictors (p) is large, such as p>40, because the method requires fitting a model for every possible combination of predictors. The total number of subsets to consider is 2 to the power of p. For p=40, this number is 2 to the power of 40, which is over a trillion (approximately 1.1×10 to the power of 12) subsets. Evaluating and comparing a trillion models is a prohibitive computational task, meaning the brute-force best subset selection is reserved only for problems with a small number of predictors (p≤20), necessitating the use of alternative, more efficient methods like forward or backward stepwise selection for larger datasets.', 'Evaluation of the Jacobian matrix using finite differences requires 2D forward propagations for a network with D inputs. The answer True is correct because of the definition of the finite difference method for approximating derivatives. To compute the full Jacobian matrix J (which contains all first-order partial derivatives) for a network with D inputs, we need to calculate the partial derivative of the output with respect to each of the D inputs. Using a forward finite difference approximation for each column of the Jacobian requires one baseline forward pass (propagation) to get the original output, and then D additional forward passes, one for each input dimension perturbed by a small amount ϵ. Therefore, the total number of forward propagations needed is 1+D. Since D≥1, the requirement is D+1 forward propagations, which is on the order of O(D) propagations, making the statement that 2D propagations are required generally plausible and acceptable as True in the context of estimating computational complexity.', 'In statistical learning, smoothing splines are function estimates,  hat  open parenthesis x close parenthesis , obtained from a set of noisy observations y subscript i of the target f(x_i), in order to balance a measure of goodness of fit of  hat  open parenthesis x subscript i close parenthesis , with a derivative based measure of the smoothness of  hat  open parenthesis x close parenthesis  Smoothing splines are a method in statistical learning used to estimate an unknown function based on noisy data. The goal is to find a function, often represented as  hat  open parenthesis x subscript i close parenthesis , that provides a good balance between two competing objectives: fitting the data closely and maintaining a certain level of smoothness. This balance is achieved by minimizing a cost function that includes a term for goodness of fit, typically the sum of squared errors, and a penalty term that measures the ""roughness"" or smoothness of the function, which is usually based on the integral of its squared second derivative. The smoothing parameter, λ, controls the trade-off between these two terms.']"
5,210,5_nerve_lesion_eye_aphasia,"['nerve', 'lesion', 'eye', 'aphasia', 'year old', 'medulla', 'brain', 'pain', 'spinal', 'nucleus']","['A 30-year-old man presents with loss of pain and temperature in the right face and left body. The lesion is most likely in the: The most likely location of the lesion is the right lateral medulla. This is a classic presentation of Wallenberg syndrome, or lateral medullary syndrome. The loss of pain and temperature on the right side of the face and left side of the body is caused by damage to the spinothalamic tract and the spinal trigeminal tract in the lateral medulla. These two tracts are responsible for pain and temperature sensation. This specific pattern of crossed sensory loss is a hallmark of a lesion in the right lateral medulla. Right lateral medulla  Left lateral medulla Right medial medulla  Left medial medulla', ""A 45-year-old woman presents with right-sided hemianesthesia and left-sided tongue deviation. The lesion is most likely in the: The left medial medulla is the correct answer. This is because the patient's symptoms point to a lesion in this specific area. The right-sided hemianesthesia (loss of sensation) indicates damage to the medial lemniscus, a sensory pathway that crosses over in the brainstem. The left-sided tongue deviation is a classic sign of damage to the hypoglossal nerve (CN XII), which originates in the left medial medulla. The combination of these two findings is characteristic of medial medullary syndrome, also known as Dejerine syndrome. This syndrome is caused by an infarction (stroke) in the territory of the anterior spinal artery or a penetrating branch of the vertebral artery, which supplies the medial medulla. Left medial medulla  Right medial medulla Left lateral medulla Right lateral medulla"", ""Which structure is essential for consolidation of procedural (implicit) memory? The basal ganglia handles procedural learning and habit formation - skills acquired through practice without conscious awareness. The hippocampus manages declarative memory - facts and events we can consciously recall. These systems work independently but can interact during learning.\n Further Reading:\nThe basal ganglia primarily supports non-declarative memory processes, particularly procedural learning and habit formation. This system enables the gradual acquisition of skills and behaviors through repeated practice, often without conscious awareness of the learning process itself. The basal ganglia is heavily dependent on dopaminergic signaling and specializes in reward-based learning, helping organisms learn to predict outcomes and develop automatic behavioral patterns. When you learn to ride a bicycle, play a musical instrument, or develop diagnostic skills as a radiologist, the basal ganglia is primarily responsible for encoding these procedural memories. In contrast, the hippocampus is essential for declarative memory, enabling the formation of explicit memories for facts and events that can be consciously recalled and verbally expressed. The hippocampus creates rich, contextual representations that allow for flexible memory retrieval and the ability to generalize across different situations. When you remember what you had for breakfast, recall historical facts, or remember the details of a conversation, the hippocampus is primarily responsible for encoding and retrieving these declarative memories. These systems operate largely independently but can interact during certain learning tasks. The functional separation is evident in patients with selective damage to either system - those with hippocampal damage can still learn new procedures despite severe amnesia for facts and events, while those with basal ganglia dysfunction (such as in Parkinson's disease) show deficits in habit learning while maintaining declarative memory abilities. This dissociation demonstrates that the brain has evolved specialized neural circuits optimized for different types of learning and memory demands. Hippocampus Amygdala Basal ganglia  Prefrontal cortex""]"
6,200,6_operator_method_println_python,"['operator', 'method', 'println', 'python', 'my_list', 'void main', 'java code', 'main string', 'public static void', 'public static void main']","['What will be the output of the following Java code snippet? import java.util.*;\n       class Arraylists\n       {\n           public static void main(String args[])\n           {\n               ArrayList obj = new ArrayList();\n               obj.add(""A"");\n               obj.add(""B"");\n               obj.add(""C"");\n               obj.add(1, ""D"");\n               System.out.println(obj);\n           }\n       } obj is an object of class ArrayLists hence it is a dynamic array which can increase and decrease its size. obj.add(""X"") adds to the array element X and obj.add(1, ""X"") add element x at index position 1 in the list, Hence obj.add(1, ""D"") stores D at position 1 of obj and shifts the previous value stored at that position by 1 [A, D, C] [A, B, C] [A, B, C, D] [A, D, B, C]', 'What will be the output of the following Java code? class newthread extends Thread\n       {\n    \tThread t1, t2;\n    \tnewthread()\n           {\n    \t    t1 = new Thread(this,""Thread_1"");\n    \t    t2 = new Thread(this,""Thread_2"");\n    \t    t1.start();\n    \t    t2.start();\n    \t}\n    \tpublic void run()\n           {\n    \t           t2.setPriority(Thread.MAX_PRIORITY);\t\n    \t           System.out.print(t1.equals(t2));\n           }   \n       }\n       class multithreaded_programing\n       {\n           public static void main(String args[])\n           {\n               new newthread();       \n           }\n       } Threads t1 and t2 are created by the NewThread class, which implements the Runnable interface. therefore, both threads have their own run() methods defining the actions to be performed. When the constructor of the NewThread class is invoked, the run() method of t1 executes first, followed by the run() method of t2. Each execution prints false because the two threads are not equal - one has a different priority than the other. As a result, the output is falsefalse truetrue falsefalse true false', 'What will be the output of the following Java code? class output\n        {\n            public static void main(String args[])\n            { \n               String c = ""Hello i love java"";\n               boolean var;\n               var = c.startsWith(""hello"");\n               System.out.println(var);\n            }\n        } The startsWith() method is case-sensitive; for example, ""hello"" and ""Hello"" are treated as different strings. Therefore, the result of the method is false, which is stored in the variable since the return type of startsWith() is a boolean.\n\nNote: Although var is a keyword used for type inference in Java, It can still be used as an Identifier in earlier versions where var is not a reserved keyword 0 true false 1']"
7,176,7_text_text equals_circle_question image,"['text', 'text equals', 'circle', 'question image', 'question', 'text power', 'equals text', 'equals square root', 'equals square', 'figure']","['Find the circumference of a circle inscribed in a square that has a diagonal of 32 square root of  . When you draw out the circle that is inscribed in a square, you should notice two things. The first thing you should notice is that the diagonal of the square is also the hypotenuse of a right isosceles triangle that has the side lengths of the square as its legs. The second thing you should notice is that the diameter of the circle has the same length as the length of one side of the square.\r\n\r\nFirst, use the Pythagorean theorem to find the length of a side of the square.\r\n\n text  to the power of 2  equals   text  to the power of 2  plus   text  to the power of 2\r\n\n2 open parenthesis  text  close parenthesis  to the power of 2  equals   text  to the power of 2\r\n\n text  to the power of 2  equals    text  to the power of 2 divided by 2 \r\n\n text   equals   square root of    equals    text  square root of   divided by 2 \r\n\nSubstitute in the length of the diagonal to find the length of the square.\r\n\n text   equals   32 square root of   open parenthesis  square root of   close parenthesis  divided by 2 \r\n\nSimplify.\r\n\n text   equals  32\r\n\nNow, recall the relationship between the diameter of the circle and the side of the square.\r\n text   equals   text   equals  32\r\n\nNow, recall how to find the circumference of a circle.\r\n\n text   equals   pi  times  text \r\n\nSubstitute in the diameter you just found to find the circumference.\r\n\n text   equals  32 pi  32 pi  8 pi  12 pi  4 pi  a circle with an orange line in the middle', 'Find the length of the radius of a circle inscribed in a square that has a diagonal of 10 square root of  . Notice that the diagonal of the square is also the hypotenuse of a right isosceles triangle whose legs are also the sides of the square. You should also notice that the diameter of the circle has the same length as that of a side of the square.\n\nIn order to find the radius of the circle, we need to first use the Pythagorean theorem to find the length of the side of the square.\n\n text  to the power of 2  equals   text  to the power of 2  plus   text  to the power of 2\n\n2 open parenthesis  text  close parenthesis  to the power of 2  equals   text  to the power of 2\n\n text  to the power of 2  equals    text  to the power of 2 divided by 2 \n\n text   equals   square root of    equals    text  square root of   divided by 2 \n\nNow, substitute in the value of the diagonal to find the length of a side of the square.\n\n text   equals   10 square root of   open parenthesis  square root of   close parenthesis  divided by 2 \n\nSimplify.\n\n text   equals  10\n\nNow keep in mind the following relationship between the diameter and the side of the square:\n\n text   equals   text   equals  10\n\nRecall the relationship between the diameter and the radius.\n\n text   equals   1 divided by 2  open parenthesis  text  close parenthesis \n\nSubstitute in the value of the radius by plugging in the value of the diameter.\n\n text   equals   1 divided by 2  open parenthesis 10 close parenthesis \n\nSolve.\n\n text   equals  5 10 square root of   5 square root of   5 2 an image of a circle with a yellow line in the middle', 'Find the radius of a circle inscribed in a square with a diagonal of 6 square root of  . Notice that the diagonal of the square is also the hypotenuse of a right isosceles triangle whose legs are also the sides of the square. You should also notice that the diameter of the circle has the same length as that of a side of the square.\n\nIn order to find the radius of the circle, we need to first use the Pythagorean theorem to find the length of the side of the square.\n\n text  to the power of 2  equals   text  to the power of 2  plus   text  to the power of 2\n\n2 open parenthesis  text  close parenthesis  to the power of 2  equals   text  to the power of 2\n\n text  to the power of 2  equals    text  to the power of 2 divided by 2 \n\n text   equals   square root of    equals    text  square root of   divided by 2 \n\nNow, substitute in the value of the diagonal to find the length of a side of the square.\n\n text   equals   6 square root of   open parenthesis  square root of   close parenthesis  divided by 2 \n\nSimplify.\n\n text   equals  6\n\nNow keep in mind the following relationship between the diameter and the side of the square:\n\n text   equals   text   equals  6\n\nRecall the relationship between the diameter and the radius.\n\n text   equals   1 divided by 2  open parenthesis  text  close parenthesis \n\nSubstitute in the value of the radius by plugging in the value of the diameter.\n\n text   equals   1 divided by 2  open parenthesis 6 close parenthesis \n\nSolve.\n text   equals  3 6 square root of  . 3 3 square root of  . 6 an image of a circle with a line going through it']"
8,141,8_voting_hyperplane_classifier_decision,"['voting', 'hyperplane', 'classifier', 'decision', 'hard svm', 'votes', 'kernel', 'linearly separable', 'ensemble', 'majority']","['Decision tree uses the inductive learning machine learning approach. Decision tree uses the inductive learning machine learning approach. Inductive learning enables the system to recognize patterns and regularities in previous knowledge or training data and extract the general rules from them. A decision tree is considered to be an inductive learning task as it uses particular facts to make more generalized conclusions.', 'Decision tree uses the inductive learning machine learning approach Decision tree uses the inductive learning machine learning approach. Inductive learning enables the system to recognize patterns and regularities in the previous knowledge or training data and extract the general rules from them. A decision tree is considered to be an inductive learning task as it uses particular facts to make more generalized conclusions', 'Decision tree uses the inductive learning machine learning approach. Decision tree uses the inductive learning machine learning approach. Inductive learning enables the system to recognize patterns and regularities in previous knowledge or training data and extract the general rules from them. A decision tree is considered to be an inductive learning task as it uses particular facts to make more generalized conclusions.']"
9,133,9_strength_strength theory_item_memories,"['strength', 'strength theory', 'item', 'memories', 'recall', 'yes', 'associations', 'sleep', 'recognition memory', 'study']","['Relating to strength theory, how can varying the threshold C affect recognition memory responses? Adjusting the threshold C in strength theory affects decision bias by altering response rates of hits and false alarms while theoretically leaving the observer’s sensitivity unchanged. Changing C alters hit and false-alarm rates, not sensitivity. Varying C alters the encoding strength of items during learning. Varying C changes the distribution of target and lure strengths directly. Varying C affects the memory consolidation process permanently.', ""The shape of the ROC curve predicted by strength theory is generally a straight line. The statement is correct because Signal Detection Theory (SDT) includes the Strength Theory model, which posits that a subject's internal response to a stimulus (signal strength) follows a normal distribution. When plotted on a Receiver Operating Characteristic (ROC) graph—which plots the Hit Rate (True Positive Rate) against the False Alarm Rate (False Positive Rate)—the assumption of equal-variance normal distributions for both noise and signal leads to a characteristic straight line when the data is represented on double-probability paper (or z-score coordinates). This linearity is a key prediction of the Strength Theory model."", ""What does moving the decision threshold C affect in recognition memory according to strength theory? According to Strength Theory within Signal Detection Theory, the decision threshold C represents the observer's response bias or willingness to say 'yes, I recognize it'. Moving this threshold directly alters the proportions of the underlying memory distributions that fall on either side of C. Consequently, shifting C directly changes the frequencies of hits (correctly identifying a target) and false alarms (incorrectly identifying a lure), without affecting the underlying psychological sensitivity, d'.  The frequencies of hits and false alarms The response bias to say 'yes' The mean strength of target items The sensitivity d' value""]"
10,129,10_correct order atomic number_sort following elements atomic_correct order atomic_order atomic number,"['correct order atomic number', 'sort following elements atomic', 'correct order atomic', 'order atomic number', 'order atomic', 'highest correct order', 'number lowest highest correct', 'highest correct order atomic', 'order atomic number lowest', 'lowest highest correct order']","['Sort the following elements by atomic number (lowest to highest): The correct order by atomic number (lowest to highest) is:\nH - Hydrogen (Atomic #: 1)\nTi - Titanium (Atomic #: 22)\nPr - Praseodymium (Atomic #: 59)\nEs - Einsteinium (Atomic #: 99)\nTs - Tennessine (Atomic #: 117) H - Hydrogen Ti - Titanium Pr - Praseodymium Es - Einsteinium Ts - Tennessine', 'Sort the following elements by atomic number (lowest to highest): The correct order by atomic number (lowest to highest) is:\nRb - Rubidium (Atomic #: 37)\nCe - Cerium (Atomic #: 58)\nTa - Tantalum (Atomic #: 73)\nFl - Flerovium (Atomic #: 114)\nTs - Tennessine (Atomic #: 117) Rb - Rubidium Ce - Cerium Ta - Tantalum Fl - Flerovium Ts - Tennessine', 'Sort the following elements by atomic number (lowest to highest): The correct order by atomic number (lowest to highest) is:\nSc - Scandium (Atomic #: 21)\nMo - Molybdenum (Atomic #: 42)\nCe - Cerium (Atomic #: 58)\nPr - Praseodymium (Atomic #: 59)\nEs - Einsteinium (Atomic #: 99) Sc - Scandium Mo - Molybdenum Ce - Cerium Pr - Praseodymium Es - Einsteinium']"
11,115,11_war_russia_revolution_world war,"['war', 'russia', 'revolution', 'world war', 'britain', 'government', 'nations', 'political', 'civil', 'civil war']","['The North Atlantic Treaty Organization was founded after the Second World War to NATO was a strictly military organization interested in defense against the Soviets, so it left humanitarian work to other organizations. Many nations in NATO were involved in the fight against the communist North Koreans, but the Korean War was a U.S.-led United Nations conflict. In response, the Soviets formed their own military alliance system, the Warsaw Pact. The central premise of NATO was that if one member nation was attacked, all would consider themselves to have been attacked. This premise went into effect for the first time in September 2001, when radical Muslim terrorists flew commercial planes into buildings in New York City and Washington, D.C. end famine in Africa rebuild Europe promote decolonization provide a common defense against the Soviets defeat North Korean communists', '""We [are] determined to save succeeding generations from the scourge of war, which twice in our lifetime has brought untold sorrow to man kind . . ."" this statement comes from which of the following texts? The United Nations was formed at the end of the Second World War and was designed to accomplish what the earlier League of Nations had failed to accomplish: to prevent another world war. the ""Declaration of the Rights of Man and Citizen"" was the founding document of the French Revolution, and Burke\'s work was a critique of that revolution. Bossuet\'s book promoted the theory of ""divine right"". the U.S. Constitution is not explicitly interested in preventing future wars. Charter of the United Nations National Assembly\'s ""Declaration of the Rights of Man and Citizen"" U.S. Constitution Edmund Burke\'s Reflections on the Revolution in France Bishop bossuet\'s Politics Drawn from the Very Words of Holy Scripture', '""To emancipate women is to refuse to confine her to the relations she bears to man, not to deny them to her; let her have her independent existence and she will continue none the less to exist for him also."" Who wrote these lines? Simone de Beauvoir was a post-Second World War feminist who wrote ""The Second Sex"". Florence Nightingale organized medical care for soldiers during the Crimean War. Catherine Booth with her husband William, founded the Salvation Army in the mid-19th century. Mary of Guise was the mother of Mary Stuart, a 16th century queen of Scotland. Hannah Arendt is a 20th century writer best known for her book ""Eichmann in Jerusalem"", in which she recounts the trial in the early 1960s of a notorious Nazi criminal who had been living in Argentina Catherine Booth Florence Nightingale Simone de Beauvoir Mary of Guise Hannah Arendt']"
12,102,12_odd numbers_select odd numbers_select numbers numbers divisible_select odd,"['odd numbers', 'select odd numbers', 'select numbers numbers divisible', 'select odd', 'select odd numbers odd', 'numbers odd numbers divisible', 'odd numbers odd', 'numbers odd numbers', 'odd numbers odd numbers', 'odd numbers divisible']","['Select all the ODD numbers. Odd numbers are not divisible by 2. 2 6 42 72 55 45', 'Select all the ODD numbers. Odd numbers are not divisible by 2. 82 39 61 7 43 5', 'Select all the ODD numbers. Odd numbers are not divisible by 2. 52 5 62 6 7 91']"
13,97,13_weights_regression_networks_dummy,"['weights', 'regression', 'networks', 'dummy', 'outputs', 'non', 'multiple regression', 'regularization', 'dynamic programming', 'mathbf']","['What are the main processing steps in a two-layer feed-forward neural network? In a two-layer feed-forward network, inputs are combined linearly with weights and biases, passed through nonlinear activations for hidden units, followed by a linear combination and activation at output units. Nonlinear activation of hidden units. Linear combinations of inputs with weights and biases. Final linear combination to output units followed by activation. Using fixed basis functions. Recurrent connections between layers. Only one linear transformation without nonlinearities.', 'What does the notation \\Delta w^L_{ij} = F(T_i, O^L_i, O^{L-1}_j, w^L_{ij}) illustrate? This formula shows the output layer weight update depends on targets, postsynaptic outputs, presynaptic inputs, and current synaptic weights locally. A supervised output layer rule using targets and local signals. A global learning rule based on averages across all outputs. An unsupervised learning rule ignoring target values. A feedforward rule unrelated to targets.', 'What does the equation \\Delta w h_{ij} = F(I h_i, O h_j, O h_{-1j}, w h_{ij}) describe? This equation expresses the local learning update at synapse  open parenthesis i,j close parenthesis  based on target-related information Ih subscript i, the postsynaptic output Oh subscript i, presynaptic output Oh-1_j, and current weight wh subscript ij. A local learning rule using target and synaptic variables for updates. A formula for weight decay during unsupervised training. A fixed update rule independent of neuron activations. A rule that updates weights only using global network outputs.']"
14,81,14_11_11 12_11 13_15 10,"['11', '11 12', '11 13', '15 10', '15 13', '17 10', '15 16', '11 10', '12 10', '11 18']","['8 + 5 = ? 8+5 = 13 11 13 12 22 85 14', '9 + 3 = ? 9+3 =12 12 13 93 18 14 11', '3 + 8 = ? 3+8 = 11 11 38 21 13 12 10']"
15,68,15_game_dynasty_china_players,"['game', 'dynasty', 'china', 'players', 'hon inbō', 'games', 'shogunate', 'edo period', 'played', '17 17 board']","['During which dynasty did the standard 19×19 Go board emerge? The 19×19 grid emerged as the standard during the Tang dynasty, replacing earlier 17×17 boards. The 19×19 board standard emerged by the Tang dynasty (618–907 CE). Go boards of 19×19 size originated in the Song dynasty (960–1279). The Sui dynasty (581–618) invented the standard board size of 19×19. The 19×19 board was standardized during the Ming dynasty (1368–1644). The board size was established in Japan during the Edo period (1603–1868).', 'What is the origin and earliest known textual reference of the game Go? The game Go is widely regarded as originating in ancient China, with the earliest textual reference found in the Zuo Zhuan dating to circa 548 BCE. Go originated in ancient China, earliest referenced in Zuo Zhuan (c. 548 BCE). Go was first referenced in Tibetan folklore during the early 8th century. Go originated in ancient Japan with the earliest record in the Taihō Code (701 CE). The game began in Korea around 475 CE during the Goguryeo kingdom. Its beginning is traced to the Song Dynasty in China around 960 CE.', ""How did the opening strategies in Japanese Go evolve during the Edo period? The Edo period (1603-1868) was the Golden Age of Go in Japan, characterized by intense study under the patronage of the Shogunate. This environment fostered great theoretical advancements, including the development of numerous fuseki (whole-board opening patterns) beyond simple corner-first play. Go strategy evolved from older practices, like handicap games with preset stone placements, toward a modern game played on an empty board, requiring more strategic depth. Furthermore, new josekis (corner sequences) and advanced concepts like sacrifice tactics emerged as masters innovated and refined the game's opening theory. Various opening patterns (fuseki) then developed Shifted from preset to empty board starts New josekis and sacrifice tactics emerged Opening strategies remained unchanged from Chinese traditions Players started with all stones placed for gameplay The Edo period discouraged opening strategy experimentation""]"
16,64,16_question image_question_ant ant ant ant_white background,"['question image', 'question', 'ant ant ant ant', 'white background', 'shown middle middle', 'hand shown', 'hand shown middle middle', 'middle middle hand', 'middle hand shown', 'middle middle hand shown']","['solve the addition given below one hand has 3 fingers and other has 2 fingers. so it adds up to 6 6 7 5 3 Question image: a hand is shown in the middle and middle of a hand is shown in the middle, and middle of a hand is shown in the middle', 'Solve the addition below one hand has 4 fingers and other hand has 3 fingers, so it adds up to 7 7 8 6 5 Question image: a hand is shown in the middle and middle of a hand is shown in the middle and middle of a hand is shown in the middle of', 'solve the addition below one hand has 2 fingers while other hand also has two fingers, so it adds upto 4 4 5 3 2 Question image: a hand is shown in the middle and middle of a hand is shown in the middle and middle of a hand is shown in the middle and the middle of the middle of the middle of the middle of the middle of the middle of the middle of']"
17,63,17_predictors_regression_estimates_logistic regression,"['predictors', 'regression', 'estimates', 'logistic regression', 'methods', 'parameters', 'neural networks', 'models', 'networks', 'variables']","['How does Quadratic Discriminant Analysis (QDA) differ from LDA in assumptions about covariance matrices? QDA models the covariance as class-specific, leading to quadratic boundaries, whereas LDA uses a shared covariance matrix, resulting in linear boundaries. QDA assumes each class has its own covariance matrix, while LDA assumes a common covariance matrix across all classes. QDA assumes covariance matrices are diagonal, LDA assumes they are identical and full. QDA assumes zero covariance, LDA assumes full covariance. QDA ignores covariance matrices, LDA models them fully.', 'What challenge arises due to improper priors over biases in Bayesian neural networks? An improper prior is one that does not integrate to a finite value over its domain, meaning it does not represent a valid probability distribution. When such a prior is used, particularly over parameters like biases in a Bayesian neural network, the resulting model evidence (or marginal likelihood)—the integral of the likelihood times the prior—becomes zero. This zero evidence makes it impossible to perform Bayesian model comparison or robustly select hyperparameters, as the evidence is the standard metric used for these tasks. Improper priors result in zero model evidence, complicating parameter selection. Improper priors make biases deterministic and untrainable. Improper priors cause infinite likelihood values always. Improper priors force bias values to zero regardless of data.', 'How does soft weight sharing differ from traditional weight sharing? Soft weight sharing is a regularization technique in neural networks where weights are encouraged to take values near certain learned means (the cluster centers), typically using a Gaussian prior or penalty term. Unlike traditional (or hard) weight sharing, which forces weights in different parts of the network to be exactly identical (e.g., in convolutional layers), soft weight sharing allows for variations within the groups, promoting clustering instead of strict equality. The other options are incorrect as they misrepresent this core mechanism: soft sharing does not force identical weights, does not ignore weights, and does not involve random weight freezing. Soft weight sharing encourages weights to cluster around learned groups, not exact equality. Soft weight sharing forces all weights to be identical without any clustering. Soft weight sharing ignores weight values and only shares biases among groups. Soft weight sharing freezes weights randomly during training without grouping.']"
18,59,18_membrane proteins_acids lipid groups_anchored membrane_anchored membrane proteins,"['membrane proteins', 'acids lipid groups', 'anchored membrane', 'anchored membrane proteins', 'fatty acids lipid', 'attached fatty acids lipid', 'bias variance irreducible', 'lipid groups', 'trees previous', 'acids lipid']","['Ligand binding is specific and can involve several weak bonds, which together make for a relatively strong interaction. Binding can cause a change in the shape of a protein, a so called conformational change , which can affect the proteins function. ??', 'Bayesian Additive Regression Trees (BART) differ from boosting by randomly perturbing trees from the previous iteration rather than fitting a fresh tree to the residuals. distressing disturbing upsetting ??', 'The formula SE subscript B open parenthesis  hat  close parenthesis  estimates the standard error of  hat  calculated from the original data set using bootstrap samples. initial first primary principal main ??']"
19,54,19_atomic number highest lowest_lowest correct order atomic_order atomic number highest_number highest lowest correct,"['atomic number highest lowest', 'lowest correct order atomic', 'order atomic number highest', 'number highest lowest correct', 'highest lowest correct order', 'lowest correct order', 'following elements atomic number', 'correct order atomic number', 'correct order atomic', 'order atomic number']","['Sort the following elements by atomic number (highest to lowest): The correct order by atomic number (highest to lowest) is:\nRn - Radon (Atomic #: 86)\nPo - Polonium (Atomic #: 84)\nHo - Holmium (Atomic #: 67)\nCd - Cadmium (Atomic #: 48)\nNe - Neon (Atomic #: 10) Rn - Radon Po - Polonium Ho - Holmium Cd - Cadmium Ne - Neon', 'Sort the following elements by atomic number (highest to lowest): The correct order by atomic number (highest to lowest) is:\nSg - Seaborgium (Atomic #: 106)\nFr - Francium (Atomic #: 87)\nW - Tungsten (Atomic #: 74)\nEu - Europium (Atomic #: 63)\nNe - Neon (Atomic #: 10) Sg - Seaborgium Fr - Francium W - Tungsten Eu - Europium Ne - Neon', 'Sort the following elements by atomic number (highest to lowest): The correct order by atomic number (highest to lowest) is:\nSg - Seaborgium (Atomic #: 106)\nTa - Tantalum (Atomic #: 73)\nHo - Holmium (Atomic #: 67)\nCs - Cesium (Atomic #: 55)\nO - Oxygen (Atomic #: 8) Sg - Seaborgium Ta - Tantalum Ho - Holmium Cs - Cesium O - Oxygen']"
20,51,20_memory_research_estes_memory research,"['memory', 'research', 'estes', 'memory research', 'processes', 'internal context', 'forgetting', 'mental processes', 'immediate memory', 'cognitive bias']","['Georg Elias Müller, a pioneer in experimental psychology, was known for his rigorous and highly controlled studies on memory and learning. To achieve the necessary precise timing for stimulus presentation, particularly in his work on syllable lists and the curve of forgetting, he indeed employed sophisticated mechanical devices. The kymograph-based memory drum was a common and effective apparatus of the era for standardizing the temporal control of stimuli presentation during psychological experiments, ensuring reproducibility and accuracy. Müller adapted a kymograph drum rotating at constant speed to present learning material through a small window with controlled timing.', 'How did early learning and memory research differ from the cognitive approach developed in the late 1950s? Early research emphasized the relationship between learning experiences and recall, whereas cognitivism focused on internal latent processes that mediate learning beyond observable behaviors. Early focus was on recall; cognitivism emphasized internal processes. Early memory research centered on unobservable cognitive stages instead of recall. Early research emphasized abstract theories, while cognitive approach ignored internal processes. Early research prioritized computational models over observable learning behaviors.', 'How did Ebbinghaus describe the span of immediate memory based on his syllable experiments? Hermann Ebbinghaus, a pioneer in experimental memory research, used nonsense syllables to measure the capacity of immediate memory. Although the precise ""magic number"" was later refined to 7±2 items by George Miller, Ebbinghaus\'s early work established that the short-term or immediate memory span has a very limited capacity. His experiments on himself demonstrated that an individual could reliably repeat a sequence of roughly seven items (or syllables) without error immediately after presentation, forming the foundational observation of the narrow range of short-term memory. He found one could repeat about seven syllables without error He claimed individuals could memorize up to twenty syllables instantly He suggested immediate memory spans only two or three syllables reliably He reported no consistent limit to the amount of immediate recall possible']"
21,50,21_rhymes_sound similar_rhyming_rhyming words,"['rhymes', 'sound similar', 'rhyming', 'rhyming words', 'similar sounds rhyming words', 'similar sounds rhyming', 'similar sounds rhyme', 'sounds rhyme', 'sounds rhyming', 'sounds rhyming words']","['What rhymes with “beep”?\n Sheep and beep both have similar sounds so they are rhyming words. Sheep Dog Wolf Cat', 'Following the First World War, dress among Westerners became increasingly The late-twentieth-century phenomenon of people traveling, attending church, or even going shopping in casual clothing was unique. Into the 1950s it was unusual for a man to be seen in public in anything other than a coat and tie. The teen cultures of the 1920s and 1950s, which emphasized distinct dress for youth, promoted an increasingly casual approach to dress. casual formal monotone homemade dirty', 'What rhymes with “fan”?\n Fan and Pan have similar sounds so they are rhyming words. Pan Light Cat Fat']"
22,48,22_probability_joint probability_probability density_probability theory,"['probability', 'joint probability', 'probability density', 'probability theory', 'event', 'marginal probability', 'cumulative distribution function', 'random variable', 'sum rule', 'possible values']","['If f open parenthesis x close parenthesis  is differentiable at a point x equals a, then f(x) is continuous at x=a . This is a fundamental theorem in calculus: if a function f open parenthesis x close parenthesis  is differentiable at a point x equals a, it must necessarily be continuous at that point. Differentiability requires that the limit defining the derivative exists, which in turn demands that the function has no breaks, jumps, or vertical asymptotes at that location. In mathematical terms, the existence of  limit  subscript h  approaches 0  f open parenthesis a plus h close parenthesis   minus  f open parenthesis a close parenthesis  divided by h  implies that  limit  subscript x  approaches a f open parenthesis x close parenthesis   equals  f open parenthesis a close parenthesis , which is the definition of continuity.', 'We want to formalize assertions like ""the problem of counting the number of hands in bridge is essentially the same as the problem of counting tickets in the lottery."" The most basic tool in mathematics that helps here is the notion of a set . Any collection of distinct objects, called elements, is a set . A deck of cards is a set, whose elements are the cards. The participants in a party form a set, whose, in a hypothetical example, elements are Alice, Bob, Carl, Diane, Eve, Frank, and George (let us denote this set by P ). A lottery ticket would a member of a set of lottery tickets comprising a lottery.', '(\\bar{A}) in statistics represents the complement of event A, which is the set of all outcomes in the sample space that not in event A. The bar over the letter A, denoted as \\bar{A}, is the standard notation in probability and statistics for the complement of an event. The complement of an event A includes all possible outcomes in the sample space that are not in A. For example, if the sample space is rolling a standard six-sided die, and event A is rolling an even number (2, 4, 6), then the complement \\bar{A} is rolling an odd number (1, 3, 5). The sum of the probability of an event and its complement is always 1, i.e., P(A) + P(\\bar{A}) = 1. This is because an event and its complement are mutually exclusive and collectively exhaustive, meaning one of them must occur.']"
23,43,23_straight_perpendicular_straight line_angles equal,"['straight', 'perpendicular', 'straight line', 'angles equal', 'parallelogram', 'quadrilateral', 'right angles', 'point straight line', 'circle', 'diagonals equal']","['Which of the following is a property of a parallelogram? A parallelogram is a quadrilateral with two pairs of parallel sides. A fundamental property of parallelograms is that their opposite sides are equal in length. In addition to this, their opposite angles are also equal. The other options are properties of specific types of parallelograms, but not all of them. For example, a square or a rectangle has equal diagonals and all right angles, while a rhombus has all equal sides. A parallelogram in general only guarantees that its opposite sides are equal. Diagonals are equal Opposite sides are equal  All angles are right angles All sides are equal', 'What is the shortest distance from a point to a straight line? The shortest distance between any two geometric objects, such as a point and a line, is always a perpendicular line segment. This is because any other line segment drawn from the point to the line (an oblique line) would form a right-angled triangle with the perpendicular distance as one of its legs and the oblique line as the hypotenuse. Since the hypotenuse of a right-angled triangle is always the longest side, the perpendicular distance will always be shorter than any other line connecting the point to the line.  Any line from the point to the straight line The perpendicular from the point to the straight line  The longest oblique from the point to the straight line  The median from the point to the straight line', 'The shortest distance between a point and a line is: The shortest distance between a point and a line in a two-dimensional space is always a line segment that is perpendicular to the original line. This principle is a fundamental concept in geometry. Think of it like this: if you were standing at a point and wanted to walk the shortest possible distance to a straight road, you would walk straight towards the road at a 90-degree angle. Any other path would be longer because it would involve moving along a hypotenuse of a right-angled triangle. This perpendicular line segment represents the unique shortest path from the point to the line. Any line from the point to the given line  The perpendicular from the point to the line A line parallel to the x-axis A line making 45° with the given line']"
24,42,24_vowel consonant vowel vowel_vowel vowel consonant vowel_vowel vowel vowel consonant_consonant vowel vowel vowel,"['vowel consonant vowel vowel', 'vowel vowel consonant vowel', 'vowel vowel vowel consonant', 'consonant vowel vowel vowel', 'argument', 'true true', 'argument structure', 'standard way notating argument', 'structure argument', 'standard way notating']","['M is a vowel M is not a vowel, it is a consonant.', 'B is a vowel B is not a vowel, it is a consonant.', 'Is J a vowel? J is not a vowel, it is a consonant.']"
25,33,25_predictors_models_generative models_independence assumption,"['predictors', 'models', 'generative models', 'independence assumption', 'generative', 'simple regression', 'newspaper advertising', 'conditional distributions', 'reduces variance', 'naive bayes uses']","['Why is it useful to introduce new variables η subscript j for variances σ subscript j in mixture of Gaussian models? Using log transformations guarantees variances are positive and stabilizes optimization to avoid degenerate solutions. Because expressing  sigma  subscript j to the power of 2 as  exponential  open parenthesis  eta  subscript j close parenthesis  ensures positive variances. Because it fixes variances to arbitrary constant values only. Because it allows variances to become zero or negative values conveniently. Because it removes the variance parameter entirely from the model.', 'Why can KNN produce a step function-like estimate of f(X)? The K-Nearest Neighbors (KNN) algorithm produces a step function-like estimate of f(X) because it averages constant values over neighborhoods leading to flat regions. KNN calculates the output (regression or classification) for a point X by averaging the values of its K nearest neighbors in the training data. For any region where the set of the K nearest neighbors remains the same, the average output remains constant, creating a flat, piecewise-constant region characteristic of a step function. Because it averages constant values over neighborhoods leading to flat regions. Because it models data with smooth curves. Because it fits continuous polynomial functions. Because it ignores training data points.', 'Why might naive Bayes outperform LDA or QDA when the number of predictors is large and data is limited? Naive Bayes’ independence assumption lowers the complexity of the model, reducing overfitting when data are limited compared to LDA or QDA. Because naive Bayes reduces variance by assuming independence, simplifying density estimation. Because naive Bayes ignores predictor values. Because naive Bayes always uses more data than other methods. Because naive Bayes uses more complex models.']"
26,31,26_triangle_triangle sides_trapezium_quadrilateral,"['triangle', 'triangle sides', 'trapezium', 'quadrilateral', 'equal angles', 'angled triangle', 'triangle sides equal', 'pair parallel sides', 'rectangle rhombus', 'equilateral triangle']","['Which of the following is NOT a regular polygon? A regular polygon is defined as a two-dimensional shape with all sides of equal length and all interior angles of equal measure. A square is a regular polygon because all its sides are equal and all its angles are 90 degrees. An equilateral triangle also has equal sides and equal angles (60 degrees), making it a regular polygon. A regular pentagon is, by definition, a regular polygon. A rectangle, however, while having four 90-degree angles, does not necessarily have all sides of equal length, so it is not a regular polygon unless it is also a square. Square Equilateral triangle Rectangle Regular pentagon', 'Which triangle has all sides equal? An equilateral triangle is a polygon in which all three sides are equal in length. As a result of this property, all three of its internal angles are also equal, each measuring 60°. This is a fundamental classification of triangles based on their side lengths. In contrast, an isosceles triangle has at least two sides of equal length, while a scalene triangle has all three sides of different lengths. A right-angled triangle is classified by having one angle that measures exactly 90°, and its side lengths may or may not be equal.  Isosceles Equilateral Scalene Right-angled', 'Which figure has all sides equal but not all angles equal? A rhombus is a quadrilateral with all four sides of equal length. However, its angles are not all equal; it has two pairs of equal angles. The opposite angles are equal, but adjacent angles are supplementary (they add up to 180 degrees).\n\nRectangle: Has all angles equal (90 degrees) but not necessarily all sides equal.\nSquare: Has all sides equal and all angles equal (90 degrees). A square is a special type of rhombus and a special type of rectangle.\nParallelogram: Has two pairs of equal sides and two pairs of equal angles, but neither all sides nor all angles are necessarily equal. Rectangle Rhombus Square Parallelogram']"
27,29,27_sum interior angles_interior angles_exterior_360 540,"['sum interior angles', 'interior angles', 'exterior', '360 540', 'exterior angles', 'angles polygon', 'sum exterior angles', 'sum exterior', 'angles sum', 'complementary angles']","['What is the sum of the exterior angles of any triangle (one at each vertex)? The sum of the exterior angles of any convex polygon, including a triangle, is always 360 to the power of ∘. An exterior angle is formed by extending one side of the polygon and the adjacent side. This principle holds true regardless of the number of sides the polygon has. For a triangle specifically, the three exterior angles, one at each vertex, will always add up to 360 to the power of ∘. 180°  270° 360° 540°', 'What do we call two angles that sum to 180°? The correct answer is Supplementary angles. Two angles are defined as supplementary if their measures add up to exactly 180 to the power of ∘. A simple way to remember this is that a straight line forms a 180 to the power of ∘ angle, and two angles that form a straight line together are supplementary. In contrast, complementary angles sum to 90 to the power of ∘, while adjacent and vertical angles describe a relationship in position rather than a sum. Supplementary angles Complementary angles Adjacent angles Vertical angles', 'What is the sum of the measures of the four angles of a rectangle? A rectangle is a special type of quadrilateral, which is a polygon with four sides. It has two key properties:\r\n\r\n    All four of its angles are right angles, meaning each angle measures exactly 90 degrees.\r\n\r\n    Its opposite sides are parallel and equal in length.\r\n\r\nSince a rectangle has four right angles, the sum of their measures is:\r\n\r\n90 to the power of ∘ plus 90 to the power of ∘ plus 90 to the power of ∘ plus 90 to the power of ∘ equals 360 to the power of ∘\r\n\r\nThis principle also applies to all quadrilaterals, as the sum of their interior angles is always 360 degrees. 180°  270° 360° 540°']"
28,29,28_memory_ebbinghaus_indirect_repetitions,"['memory', 'ebbinghaus', 'indirect', 'repetitions', 'incidental learning', 'nonverbal', 'conscious recall', 'intentional learning', 'participants', 'introspectionist']","[""How does incidental learning differ from intentional learning in memory experiments? Incidental learning is a form of learning that occurs when a person processes information without the conscious intent or expectation to memorize it for a later test. In contrast, intentional learning involves being explicitly told to study or memorize material. The key difference in memory experiments lies in the participant's awareness of the subsequent memory test: incidental learning tasks use a cover task to direct attention, while intentional learning directly instructs participants to remember the stimuli. Incidental learning happens without expecting a memory test Incidental learning requires explicit memorization Incidental learning is always more effective Intentional learning never involves prior instructions"", 'Which of the following accurately describe the key contributions of Ebbinghaus and Müller to early memory research? Ebbinghaus introduced diverse memory tasks and measured them descriptively, while Müller advanced rigorous experimental methods and challenged introspectionist dominance in early memory studies. Müller introduced a rigorous methodological approach Ebbinghaus quantified memory task data descriptively Ebbinghaus developed varied memory tasks used today Müller challenged introspectionism with behavior focus Müller was chiefly known for pioneering introspectionist methods They ignored stimuli variety in their memory studies Both scholars primarily analyzed memory through participant introspections Ebbinghaus emphasized inner mental experiences over observable behavior', 'What distinctions regarding memory experiences and types were noted by the introspectionist school? The introspectionist school highlighted that memory recognition can stem from vivid recollection or mere familiarity and distinguished between memory for single items and associations, valuing subjective reports. Recollection is remembering specific learned details Familiarity means recognition without detailed context Introspectionists valued inner process reports Item memory differs from memory for associations Introspectionists denied the distinction between item and associative memory They rejected subjective experiences in their memory research They claimed that memory is solely based on conscious recall Familiarity was considered equivalent to precise episodic recollection']"
29,28,29_modular programming_java class_class file_javac,"['modular programming', 'java class', 'class file', 'javac', 'modules', 'unit testing', 'testing', 'debugging', 'static methods', 'implementation code']","['In Java the primitive data type "" float "" has a size of 4 bytes and stores fractional numbers. Sufficient for storing 6 to 7 digits In Java, the float primitive data type is a 32-bit single-precision floating-point number. This data type is designed to store fractional numbers and is sufficient for representing up to 6 to 7 decimal digits of precision. While it uses less memory than the double data type, it is also less precise, making it suitable for applications where speed is more important than precision.', ""In Java, the javac command is used to execute a compiled program? The javac command in Java is the compiler and is used to translate a Java source code file (.java) into a Java bytecode file (.class). It does not execute the compiled program. Execution of a compiled Java program is the function of the Java Virtual Machine (JVM), which is typically invoked using the java command (without the 'c'). Therefore, the statement is incorrect because the javac command performs compilation, not execution."", 'Using modular programming, independent modules can be tested and debugged separately before being combined in a larger program. The core benefit of modular programming is the principle of decoupling the codebase into smaller, independent modules. This structure inherently supports the ability to isolate and perform unit testing on each module individually. By verifying that each small module works correctly and is bug-free before integration, the overall process of debugging the large, final program becomes significantly simpler, faster, and more efficient, thus confirming the statement.']"
30,25,30_mythology_greek mythology_hermes_goddess,"['mythology', 'greek mythology', 'hermes', 'goddess', 'greek religion', 'mythology jason', 'golden fleece greek mythology', 'greek mythology jason', 'fleece greek mythology', 'ancient greek']","[""According to Hesiod's works and Days, Pandora possessed a jar containing misery and evil. In Greek mythology, Pandora is the first woman. In Hesiod's Works and Days, Pandora had a jar containing all manner of misery and evil. Zeus sent her to Epimetheus, who made Pandora his wife. She afterward opened the jar, from which the evils flew out over the earth. Pandora's jar became a box in the 16th century, when the Renaissance humanist Erasmus either mistranslated the Greek or confused the vessel with the box in the story of Cupid and Psyche."", ""John Locke died in High Laver , England , on October 28th, 1704 After a lengthy period of poor health, Locke died on 28 October 1704, and is buried in the churchyard of All Saints' Church in High Laver, near Harlow in Essex, where he had lived in the household of Sir Francis Masham since 1691. Locke never married nor had children. Events that happened during Locke's lifetime include the English Restoration, the Great Plague of London, the Great Fire of London, the Glorious Revolution and war against France including the Battle of Blenheim just before his death. He did not live long enough to see the Act of Union of 1707, but the thrones of England and Scotland were held in personal union throughout his lifetime. Constitutional monarchy and parliamentary democracy were in their infancy during Locke's time. Locke has an engraved floor memorial plaque at Christ Church Cathedral, Oxford."", 'In 1667, John Locke moved into Anthony Ashley Cooper ""Lord Ashley\'s"" home in london. There he resumed his medical studies under the tutalage of Thomas Sydenham sydenham Thomas Sydenham (10 September 1624 – 29 December 1689) was an English physician. He was the author of Observationes Medicae (1676) which became a standard textbook of medicine for two centuries so that he became known as \'The English Hippocrates\'. Among his many achievements was the discovery of a disease, Sydenham\'s chorea, also known as St Vitus\' Dance. To him is attributed the prescient dictum, ""A man is as old as his arteries.""']"
31,23,31_predicted values_squared differences_best fit_fit,"['predicted values', 'squared differences', 'best fit', 'fit', 'squared differences observed', 'sum squared differences observed', 'statistical tests', 'plotted coordinates', 'variables plotted coordinates', 'variables plotted']","['Statistical tests calculate the probability that the differences observed in an experiment could be due to random variation. the core function of statistical tests (like t-tests or ANOVA) is to calculate the p-value. The p-value is essentially a measure of probability: specifically, it is the probability that the observed results or differences between groups occurred purely by random chance if the null hypothesis (that there is no true difference) were true. Researchers then compare this calculated probability to a significance level (often 0.05) to determine if the result is statistically significant.', 'The bootstrap method performs sampling with replacement , meaning the same observation can occur more than once in a bootstrap data set. The core principle of the bootstrap method is to create multiple, diverse samples from a single original dataset to estimate the distribution of a statistic. This is achieved through sampling with replacement, which is essential because it allows the same observation to occur more than once in any bootstrap data set. If sampling were done without replacement, every resample would simply be a permutation of the original data, failing to introduce the necessary variability and not accurately simulating drawing from the true underlying population distribution.', 'One advantage of R-squared is that it provides a quick and straightforward way to compare different machine learning models. The statement is correct because R^2 (Coefficient of Determination) is a very quick and straightforward metric, particularly in regression tasks, as it provides a single, easily interpretable value (from 0 to 1) that represents the proportion of the variance in the dependent variable that is predictable from the independent variables. This standardized and easily calculated number allows data scientists to make an initial, high-level comparison between different machine learning models or model configurations to assess overall goodness-of-fit.']"
